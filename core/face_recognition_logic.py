# -*- coding: utf-8 -*-

# plik: core/face_recognition_logic.py
# Wersja 11.1 - Finalna wersja z ulepszonym detektorem i filtrowaniem pewno≈õci

# --- G≈Å√ìWNE IMPORTY ---
import asyncio
import json
import logging
import os
import platform
import subprocess
from concurrent.futures import ProcessPoolExecutor
from pathlib import Path
from typing import Optional

# Kluczowa biblioteka do oblicze≈Ñ matematycznych na wektorach
import numpy as np

# Modu≈Ç do limitowania zasob√≥w (pamiƒôci RAM), specyficzny dla Unix
try:
    import resource
    RESOURCE_AVAILABLE = True
except ImportError:
    RESOURCE_AVAILABLE = False

# G≈Ç√≥wne biblioteki do przetwarzania obraz√≥w i AI
try:
    from deepface import DeepFace
    from PIL import Image
except ImportError:
    DeepFace, Image = None, None

# Asynchroniczna obs≈Çuga bazy danych
import aiosqlite

# Biblioteka do tworzenia bogatego interfejsu w terminalu
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Confirm, Prompt
from rich.progress import Progress, BarColumn, TextColumn, SpinnerColumn

# --- IMPORTY Z W≈ÅASNYCH MODU≈Å√ìW APLIKACJI ---
from .config import (
    DOWNLOADS_DIR_BASE,
    AI_MODELS_CACHE_DIR,
    DATABASE_FILE,
)
from .utils import create_interactive_menu, check_dependency, open_image_viewer, get_key

# Importujemy funkcje z naszego nowego, zaawansowanego modu≈Çu bazy danych
from .database import (
    setup_database,
    add_person,
    get_all_people,
    update_person_name,
    delete_person,
    add_face,
    get_unknown_faces,
    tag_face,
    get_media_ids_with_indexed_faces,
    get_all_tagged_people,
    get_media_for_person,
)

# --- INICJALIZACJA GLOBALNYCH OBIEKT√ìW ---
console = Console()
logger = logging.getLogger(__name__)

# --- STA≈ÅE I KONFIGURACJA MODU≈ÅU ---
AVAILABLE_MODELS = [
    {"name": "VGG-Face", "description": "Dobry kompromis dok≈Çadno≈õci i wydajno≈õci."},
    {"name": "Facenet", "description": "Wysoka dok≈Çadno≈õƒá, ale powolny na CPU."},
    {"name": "Facenet512", "description": "Wersja Facenet, bardzo zasobo≈ºerna."},
    {"name": "ArcFace", "description": "Bardzo wysoka dok≈Çadno≈õƒá, bardzo powolny na CPU."},
    {"name": "Dlib", "description": "Najszybszy, najl≈ºejszy. Dobry dla < 4GB RAM."},
    {"name": "OpenFace", "description": "Klasyczny, szybki model."},
    {"name": "DeepFace", "description": "Lekki model, alternatywa dla Dlib."},
    {"name": "GhostFaceNet", "description": "Nowoczesny, wydajny. [bold green]Zalecany dla RPi 5.[/bold green]"},
]
MODEL_FILE_MAP = {
    "VGG-Face": "vgg_face_weights.h5", "Facenet": "facenet_weights.h5", "ArcFace": "arcface_weights.h5",
    "Dlib": "dlib_face_recognition_resnet_model_v1.dat", "OpenFace": "openface_weights.h5",
    "DeepFace": "deepface_weights.h5", "GhostFaceNet": "ghostfacenet_v1.h5", "Facenet512": "facenet512_weights.h5",
}

SETTINGS_FILE_PATH = Path("app_data/face_rec_settings.json")

# Wyb√≥r `retinaface` jako domy≈õlnego, dok≈Çadniejszego detektora twarzy
DETECTOR_BACKEND = "retinaface"

def findCosineDistance(source_representation, test_representation):
    """
    Oblicza odleg≈Ço≈õƒá kosinusowƒÖ miƒôdzy dwoma wektorami za pomocƒÖ NumPy.

    Args:
        source_representation (np.ndarray): Wektor pierwszej twarzy.
        test_representation (np.ndarray): Wektor drugiej twarzy.

    Returns:
        float: Odleg≈Ço≈õƒá kosinusowa (od 0.0 do 1.0).
    """
    a = np.asarray(source_representation)
    b = np.asarray(test_representation)
    
    # Zabezpieczenie przed dzieleniem przez zero, je≈õli kt√≥ry≈õ wektor jest pusty
    if np.linalg.norm(a) == 0 or np.linalg.norm(b) == 0:
        return 1.0  # Zwr√≥ƒá maksymalnƒÖ odleg≈Ço≈õƒá
        
    return 1 - (np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))

def findThreshold(model_name: str, distance_metric: str) -> float:
    """
    Zwraca pr√≥g weryfikacji dla danego modelu i metryki.

    Args:
        model_name (str): Nazwa modelu (np. "VGG-Face").
        distance_metric (str): Nazwa metryki (np. "cosine").

    Returns:
        float: Warto≈õƒá progowa do weryfikacji.
    """
    thresholds = {
        "VGG-Face": {"cosine": 0.40},
        "Facenet": {"cosine": 0.40},
        "ArcFace": {"cosine": 0.68},
        "Dlib": {"cosine": 0.07},
        "GhostFaceNet": {"cosine": 0.65},
    }
    # Zwraca pr√≥g dla danego modelu lub bezpiecznƒÖ warto≈õƒá domy≈õlnƒÖ
    return thresholds.get(model_name, {}).get(distance_metric, 0.40)

def _get_deepface_base_path() -> Path:
    """
    Zwraca ≈õcie≈ºkƒô bazowƒÖ dla DeepFace (katalog nadrzƒôdny dla folderu .deepface).
    
    U≈ºywa ≈õcie≈ºki z konfiguracji (AI_MODELS_CACHE_DIR), je≈õli jest dostƒôpna,
    w przeciwnym razie domy≈õlnie wskazuje na katalog domowy u≈ºytkownika.
    """
    if AI_MODELS_CACHE_DIR:
        return Path(AI_MODELS_CACHE_DIR)
    return Path.home()

def _get_deepface_home_path() -> Path:
    """Zwraca pe≈ÇnƒÖ ≈õcie≈ºkƒô do folderu .deepface."""
    return _get_deepface_base_path() / ".deepface"

def run_deepface_represent_in_process(img_path_str: str, model_name: str, detector_backend: str):
    """
    Uruchamia `DeepFace.represent` w osobnym, odizolowanym procesie dla stabilno≈õci.

    Args:
        img_path_str (str): ≈öcie≈ºka do pliku obrazu.
        model_name (str): Nazwa modelu AI do u≈ºycia.
        detector_backend (str): Nazwa silnika detekcji twarzy.

    Returns:
        list: Lista obiekt√≥w z wektorami twarzy lub pusta lista w razie b≈Çƒôdu.
    """
    from deepface import DeepFace
    
    # Upewniamy siƒô, ≈ºe nowy proces wie, gdzie szukaƒá modeli
    base_path = _get_deepface_base_path()
    os.environ['DEEPFACE_HOME'] = str(base_path)
    
    try:
        # Wywo≈Çujemy g≈Ç√≥wnƒÖ funkcjƒô analizujƒÖcƒÖ obraz z podanym detektorem
        return DeepFace.represent(
            img_path=img_path_str,
            model_name=model_name,
            enforce_detection=False,
            detector_backend=detector_backend
        )
    except Exception as e:
        # W razie b≈Çƒôdu w podprocesie, logujemy go i zwracamy pustƒÖ listƒô
        logger.error(f"B≈ÇƒÖd w podprocesie DeepFace dla obrazu {img_path_str}: {e}", exc_info=False)
        return []

def _initialize_deepface_env():
    """Konfiguruje ≈õrodowisko, tworzy foldery i ustawia zmienne."""
    base_path = _get_deepface_base_path()
    deepface_home_path = base_path / ".deepface"
    weights_path = deepface_home_path / "weights"
    weights_path.mkdir(parents=True, exist_ok=True)
    os.environ['DEEPFACE_HOME'] = str(base_path)
    logger.info(f"Ustawiono bazƒô dla DeepFace: {base_path}")

def _check_dependencies() -> bool:
    """Sprawdza, czy wszystkie zale≈ºno≈õci dla tego modu≈Çu sƒÖ dostƒôpne."""
    logger.debug("Sprawdzam zale≈ºno≈õci dla modu≈Çu Rozpoznawania Twarzy...")
    dependencies_ok = all([
        check_dependency("deepface", "deepface", "DeepFace"),
        check_dependency("numpy", "numpy", "NumPy"),
        check_dependency("PIL", "Pillow", "Pillow"),
        check_dependency("pandas", "pandas", "Pandas"),
#        check_dependency("tensorflow", "tensorflow", "TensorFlow"),
        check_dependency("dlib", "dlib", "Dlib (dla modelu Dlib)")
    ])
    return dependencies_ok

async def _is_model_downloaded(model_name: str) -> bool:
    """
    Sprawdza asynchronicznie, czy plik z wagami modelu istnieje na dysku.

    Args:
        model_name (str): Nazwa modelu do sprawdzenia.

    Returns:
        bool: True, je≈õli plik modelu istnieje, w przeciwnym razie False.
    """
    model_filename = MODEL_FILE_MAP.get(model_name)
    if not model_filename:
        return False
        
    model_path = _get_deepface_home_path() / "weights" / model_filename
    
    # Uruchamia synchronicznƒÖ operacjƒô sprawdzania pliku w osobnym wƒÖtku,
    # aby nie blokowaƒá g≈Ç√≥wnej pƒôtli programu.
    return await asyncio.to_thread(model_path.exists)

def set_memory_limit(gb_limit: float | None):
    """
    Ustawia limit wirtualnej pamiƒôci dla bie≈ºƒÖcego procesu (tylko Unix).

    Args:
        gb_limit (float | None): Limit pamiƒôci w gigabajtach. 
                                 None lub 0 usuwa limit.
    """
    if not RESOURCE_AVAILABLE:
        if gb_limit is not None:
            console.print("[yellow]Ostrze≈ºenie: Ustawianie limitu pamiƒôci nie jest wspierane w tym systemie.[/yellow]")
        return
        
    try:
        if gb_limit and gb_limit > 0:
            limit_bytes = int(gb_limit * 1024**3)
            resource.setrlimit(resource.RLIMIT_AS, (limit_bytes, limit_bytes))
            console.print(f"[green]‚úÖ Ustawiono limit pamiƒôci na {gb_limit} GB.[/green]")
        else:
            # Ustawienie niesko≈Ñczonego limitu
            resource.setrlimit(resource.RLIMIT_AS, (resource.RLIM_INFINITY, resource.RLIM_INFINITY))
            console.print("[yellow]‚úÖ Usuniƒôto limit pamiƒôci.[/yellow]")
    except (ValueError, resource.error) as e:
        console.print(f"[bold red]B≈ÇƒÖd: Nie uda≈Ço siƒô ustawiƒá limitu pamiƒôci: {e}[/bold red]")

def _read_face_rec_settings() -> dict:
    """
    Wczytuje ustawienia specyficzne dla rozpoznawania twarzy z pliku JSON.
    """
    try:
        if not SETTINGS_FILE_PATH.exists():
            return {}
        with open(SETTINGS_FILE_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return {}

def _write_face_rec_settings(new_settings: dict):
    """
    Zapisuje ustawienia specyficzne dla rozpoznawania twarzy do pliku JSON.
    """
    try:
        all_settings = _read_face_rec_settings()
        all_settings.update(new_settings)
        SETTINGS_FILE_PATH.parent.mkdir(exist_ok=True, parents=True)
        with open(SETTINGS_FILE_PATH, 'w', encoding='utf-8') as f:
            json.dump(all_settings, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logger.error(f"Nie uda≈Ço siƒô zapisaƒá ustawie≈Ñ: {e}")

async def index_faces(model_name: str):
    """
    Skanuje kolekcjƒô w poszukiwaniu nowych zdjƒôƒá, wykrywa na nich twarze
    i zapisuje je w bazie danych jako "nieznane" do p√≥≈∫niejszej identyfikacji.
    """
    console.clear()
    console.print(Panel(f"üî¨ Indeksowanie Twarzy (Model: [cyan]{model_name}[/cyan]) üî¨", style="bold blue"))
    await setup_database()

    # Krok 1: Pobierz ID medi√≥w, kt√≥re ju≈º zosta≈Çy zaindeksowane dla tego modelu
    with console.status("[cyan]Sprawdzanie stanu bazy danych...[/]"):
        indexed_media_ids = await get_media_ids_with_indexed_faces(model_name)
        
    # Krok 2: Pobierz wszystkie zdjƒôcia, pomijajƒÖc te ju≈º zaindeksowane
    media_to_scan = []
    with console.status("[cyan]Pobieranie listy zdjƒôƒá do przetworzenia...[/]"):
        try:
            async with aiosqlite.connect(DATABASE_FILE) as conn:
                conn.row_factory = aiosqlite.Row
                
                # Wybieramy tylko pliki graficzne, kt√≥rych ID nie ma na li≈õcie ju≈º zaindeksowanych
                query = """
                    SELECT id, final_path FROM downloaded_media 
                    WHERE status = 'downloaded' AND final_path IS NOT NULL
                    AND (LOWER(final_path) LIKE '%.jpg' OR LOWER(final_path) LIKE '%.jpeg' OR LOWER(final_path) LIKE '%.png')
                """
                
                if indexed_media_ids:
                    placeholders = ','.join('?' for _ in indexed_media_ids)
                    query += f" AND id NOT IN ({placeholders})"
                    cursor = await conn.execute(query, indexed_media_ids)
                else:
                    cursor = await conn.execute(query)

                media_to_scan = await cursor.fetchall()
        except aiosqlite.Error as e:
            logger.error(f"B≈ÇƒÖd odczytu bazy danych: {e}", exc_info=True)
            return

    if not media_to_scan:
        console.print("[green]‚úÖ Twoja baza twarzy jest ju≈º aktualna. Nie znaleziono nowych zdjƒôƒá do indeksowania.[/green]")
        return

    if not Confirm.ask(f"\nZnaleziono [cyan]{len(media_to_scan)}[/cyan] nowych zdjƒôƒá do analizy. RozpoczƒÖƒá indeksowanie?"):
        return

    # Krok 3: Przetwarzanie i zapisywanie twarzy do bazy
    total_faces_found = 0
    loop = asyncio.get_running_loop()
    pool = ProcessPoolExecutor(max_workers=1)
    try:
        with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), BarColumn(), TextColumn("{task.percentage:>3.0f}%"), transient=True) as progress:
            task = progress.add_task("[green]Indeksowanie...", total=len(media_to_scan))
            for media_record in media_to_scan:
                media_id, path_str = media_record['id'], media_record['final_path']
                path = Path(path_str)
                progress.update(task, advance=1, description=f"Skanujƒô: [dim]{path.name}[/dim]")

                if not await asyncio.to_thread(path.exists):
                    continue

                embedding_objs = await loop.run_in_executor(pool, run_deepface_represent_in_process, str(path), model_name, DETECTOR_BACKEND)
                
                for face_obj in embedding_objs:
                    # Filtr pewno≈õci, aby unikaƒá "fa≈Çszywych" twarzy
                    confidence = face_obj.get("face_confidence", 0)
                    if confidence < 0.95:
                        logger.debug(f"Pominiƒôto twarz w {path.name} z niskƒÖ pewno≈õciƒÖ: {confidence:.2f}")
                        continue

                    if "embedding" in face_obj and "facial_area" in face_obj:
                        await add_face(
                            media_id=media_id,
                            embedding=face_obj["embedding"],
                            facial_area=face_obj["facial_area"],
                            model_name=model_name
                        )
                        total_faces_found += 1
    finally:
        pool.shutdown(wait=True)

    console.print(f"\n[bold green]‚úÖ Indeksowanie zako≈Ñczone! Dodano {total_faces_found} twarzy o wysokiej pewno≈õci.[/bold green]")

async def recognize_and_tag_faces(model_name: str):
    """
    Por√≥wnuje nieznane twarze z bazy danych ze znanymi osobami i taguje dopasowania.
    """
    console.clear()
    console.print(Panel(f"üïµÔ∏è Rozpoznawanie i Tagiwanie Twarzy (Model: [cyan]{model_name}[/cyan]) üïµÔ∏è", style="bold blue"))
    await setup_database()

    # Krok 1: Pobierz wszystkie znane osoby i nieznane twarze z bazy danych
    with console.status("[cyan]Pobieranie danych z bazy...[/]"):
        known_people = await get_all_people(model_name)
        unknown_faces = await get_unknown_faces(model_name)

    if not known_people:
        console.print(f"[yellow]Brak znanych os√≥b dla modelu '{model_name}'. Dodaj kogo≈õ w menu 'ZarzƒÖdzaj osobami'.[/yellow]")
        return
    
    if not unknown_faces:
        console.print("[green]‚úÖ Brak nowych, nieznanych twarzy do rozpoznania.[/green]")
        return
        
    console.print(f"Znaleziono [cyan]{len(known_people)}[/cyan] znanych os√≥b i [cyan]{len(unknown_faces)}[/cyan] nieotagowanych twarzy.")

    # Krok 2: Por√≥wnaj ka≈ºdƒÖ nieznanƒÖ twarz z ka≈ºdƒÖ znanƒÖ osobƒÖ
    total_tagged = 0
    with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), BarColumn(), TextColumn("{task.percentage:>3.0f}%"), transient=True) as progress:
        task = progress.add_task("[green]Rozpoznawanie...", total=len(unknown_faces))
        
        threshold = findThreshold(model_name, 'cosine')

        for face in unknown_faces:
            progress.update(task, advance=1)
            
            best_match_person_id = None
            min_distance = float('inf')

            for person in known_people:
                distance = findCosineDistance(face["embedding"], person["master_embedding"])
                
                if distance < min_distance and distance < threshold:
                    min_distance = distance
                    best_match_person_id = person["person_id"]
            
            # Krok 3: Je≈õli znaleziono dopasowanie, otaguj twarz w bazie
            if best_match_person_id is not None:
                await tag_face(face["face_id"], best_match_person_id)
                total_tagged += 1
    
    console.print(f"\n[bold green]‚úÖ Rozpoznawanie zako≈Ñczone! Otagowano {total_tagged} nowych twarzy.[/bold green]")

# --- FUNKCJE OBS≈ÅUGI MENU U≈ªYTKOWNIKA ---

async def manage_people(model_name: str):
    """Wy≈õwietla interaktywne menu do zarzƒÖdzania znanymi osobami (CRUD)."""
    while True:
        console.clear()
        console.print(Panel("üë®‚Äçüë©‚Äçüëß‚Äçüë¶ ZarzƒÖdzanie Osobami üë®‚Äçüë©‚Äçüëß‚Äçüë¶", style="bold blue", subtitle=f"Model: [cyan]{model_name}[/cyan]"))
        
        with console.status("Pobieranie listy os√≥b..."):
            people = await get_all_people(model_name)

        menu_items = [
            ("Dodaj nowƒÖ osobƒô", "add"),
            ("Edytuj nazwƒô osoby", "edit"),
            ("Usu≈Ñ osobƒô", "delete"),
            ("Wy≈õwietl listƒô znanych os√≥b", "list"),
            ("Wr√≥ƒá", "exit")
        ]
        
        selected_action = await create_interactive_menu(menu_items, "Wybierz operacjƒô")

        if selected_action in ("exit", None):
            break

        if selected_action == "add":
            path_str = Prompt.ask("[cyan]Podaj ≈õcie≈ºkƒô do wyra≈∫nego zdjƒôcia osoby[/cyan]")
            image_path = Path(path_str)
            if not image_path.is_file():
                console.print("[red]B≈ÇƒÖd: Podana ≈õcie≈ºka nie jest plikiem.[/red]")
            else:
                person_name = Prompt.ask("[cyan]Podaj imiƒô i nazwisko tej osoby[/cyan]").strip()
                if person_name:
                    with console.status(f"Przetwarzanie zdjƒôcia dla [bold]{person_name}[/bold]..."):
                        embedding_objs = run_deepface_represent_in_process(str(image_path), model_name, DETECTOR_BACKEND)
                        if embedding_objs:
                            person_id = await add_person(person_name, model_name, embedding_objs[0]["embedding"])
                            if person_id:
                                console.print(f"[green]‚úÖ Pomy≈õlnie dodano '{person_name}'.[/green]")
                        else:
                            console.print(f"[red]Nie wykryto twarzy na zdjƒôciu {image_path.name}.[/red]")
                else:
                    console.print("[red]B≈ÇƒÖd: Imiƒô i nazwisko nie mo≈ºe byƒá puste.[/red]")
            Prompt.ask("\n[bold]Naci≈õnij Enter...[/]")

        elif selected_action in ("edit", "delete"):
            if not people:
                console.print("[yellow]Brak os√≥b w bazie dla tego modelu do edycji/usuniƒôcia.[/yellow]")
            else:
                person_choices = [(p['name'], p) for p in people]
                person_to_act_on = await create_interactive_menu(person_choices, f"Wybierz osobƒô do {'edycji' if selected_action == 'edit' else 'usuniƒôcia'}")
                if person_to_act_on:
                    if selected_action == 'edit':
                        new_name = Prompt.ask(f"[cyan]Podaj nowƒÖ nazwƒô dla '{person_to_act_on['name']}'[/cyan]").strip()
                        if new_name:
                            await update_person_name(person_to_act_on['person_id'], new_name)
                            console.print(f"[green]‚úÖ Nazwa zosta≈Ça zaktualizowana.[/green]")
                    elif selected_action == 'delete':
                        if Confirm.ask(f"[bold red]Czy na pewno chcesz usunƒÖƒá '{person_to_act_on['name']}'? Jej otagowane zdjƒôcia stanƒÖ siƒô ponownie 'nieznane'.[/bold red]", default=False):
                            await delete_person(person_to_act_on['person_id'])
                            console.print(f"[green]‚úÖ Usuniƒôto '{person_to_act_on['name']}'.[/green]")
            Prompt.ask("\n[bold]Naci≈õnij Enter...[/]")

        elif selected_action == "list":
            console.print(f"\n--- [bold]Lista Znanych Os√≥b (Model: {model_name})[/bold] ---")
            if not people:
                console.print("[dim]Brak os√≥b w bazie danych dla tego modelu.[/dim]")
            else:
                for person in people:
                    console.print(f"- {person['name']} (ID: {person['person_id']})")
            Prompt.ask("\n[bold]Naci≈õnij Enter...[/]")

async def review_tagged_faces():
    """Uruchamia interaktywnƒÖ przeglƒÖdarkƒô otagowanych zdjƒôƒá."""
    while True:
        console.clear()
        console.print(Panel("üñºÔ∏è PrzeglƒÖdanie Otagowanych Zdjƒôƒá üñºÔ∏è", style="bold green"))
        
        with console.status("Pobieranie listy os√≥b..."):
            people = await get_all_tagged_people()

        if not people:
            console.print("[yellow]Nie znaleziono jeszcze ≈ºadnych otagowanych os√≥b.[/yellow]")
            Prompt.ask("\n[bold]Naci≈õnij Enter, aby wr√≥ciƒá...[/]")
            return

        menu_items = [(f"{p['name']} ([cyan]{p['photo_count']} zdjƒôƒá[/cyan])", p) for p in people] + [("Wr√≥ƒá", "exit")]
        
        selected_person = await create_interactive_menu(menu_items, "Wybierz osobƒô, aby zobaczyƒá jej zdjƒôcia")

        if selected_person in ("exit", None):
            break
        
        media_files = await get_media_for_person(selected_person['person_id'])
        current_index = 0
        while True:
            if not media_files:
                console.print("[yellow]Brak zdjƒôƒá dla wybranej osoby.[/yellow]")
                break

            media = media_files[current_index]
            path = Path(media['final_path'])
            
            console.clear()
            console.print(Panel(f"Osoba: [bold cyan]{selected_person['name']}[/bold cyan] | Zdjƒôcie {current_index + 1}/{len(media_files)}", subtitle=f"[dim]{path.name}[/dim]"))

            await asyncio.to_thread(open_image_viewer, path)

            console.print("\nNawigacja: [bold](P)rawo[/bold] - nastƒôpne, [bold](L)ewo[/bold] - poprzednie, [bold](W)yj≈õcie[/bold]")
            key = await asyncio.to_thread(get_key)

            if key in ("RIGHT", "P"):
                current_index = (current_index + 1) % len(media_files)
            elif key in ("LEFT", "L"):
                current_index = (current_index - 1 + len(media_files)) % len(media_files)
            elif key in ("W", "Q", "ESC"):
                break

async def manage_ai_models():
    """Wy≈õwietla interfejs do zarzƒÖdzania pobranymi modelami AI."""
    loop = asyncio.get_running_loop()
    while True:
        console.clear()
        with console.status("[cyan]Sprawdzanie statusu modeli...[/]"):
            statuses = await asyncio.gather(*[_is_model_downloaded(m['name']) for m in AVAILABLE_MODELS])
        menu_items = [(f"{m['name']} ({'[green]Pobrany[/]' if d else '[red]Niepobrany[/]'})", m['name']) for m, d in zip(AVAILABLE_MODELS, statuses)] + [("Wr√≥ƒá", "exit")]
        selected = await create_interactive_menu(menu_items, "ü§ñ Mened≈ºer Modeli AI ü§ñ")
        if selected in ["exit", None]: break
        if await _is_model_downloaded(selected):
            console.print(f"\n[green]Model [cyan]{selected}[/cyan] jest ju≈º pobrany.[/green]")
        elif Confirm.ask(f"\nModel [cyan]{selected}[/cyan] nie jest pobrany. Pobraƒá?", default=True):
            def download(model_name):
                from deepface import DeepFace
                base_path = _get_deepface_base_path()
                os.environ['DEEPFACE_HOME'] = str(base_path)
                DeepFace.build_model(model_name)
            with Progress(SpinnerColumn(), TextColumn("[cyan]Pobieranie...[/]"), transient=True) as progress:
                progress.add_task(selected, total=None)
                try:
                    await loop.run_in_executor(None, download, selected)
                    console.print(f"\n[green]‚úÖ Model {selected} pobrany pomy≈õlnie.[/green]")
                except Exception as e:
                    console.print(f"\n[red]‚ùå B≈ÇƒÖd pobierania modelu: {e}[/red]")
        Prompt.ask("\n[bold]Naci≈õnij Enter...[/]")

async def memory_limit_menu():
    """Wy≈õwietla menu do wyboru lub ustawienia limitu pamiƒôci RAM dla procesu."""
    if not RESOURCE_AVAILABLE:
        console.print("\n[yellow]Funkcja dostƒôpna tylko w systemach Linux i macOS.[/yellow]")
        await Prompt.ask("\n[bold]Naci≈õnij Enter...[/]")
        return
    console.clear()
    settings = _read_face_rec_settings()
    current_limit = settings.get("FACE_REC_MEMORY_LIMIT_GB")
    current_limit_str = f"{current_limit} GB" if current_limit and current_limit > 0 else "Brak limitu"
    items = [("4 GB", "4"), ("6 GB", "6"), ("8 GB", "8"), ("Bez limitu", "0"), ("Wpisz warto≈õƒá", "custom"), ("Wr√≥ƒá", "exit")]
    selected = await create_interactive_menu(items, title="‚öôÔ∏è Ustaw Limit Pamiƒôci RAM ‚öôÔ∏è", subtitle=f"Aktualnie: [cyan]{current_limit_str}[/]", border_style="yellow")
    if selected in ["exit", None]: return
    try:
        limit_str = Prompt.ask("[cyan]Podaj limit w GB[/]").replace(',', '.') if selected == "custom" else selected
        limit = float(limit_str)
        if limit < 0: raise ValueError
        _write_face_rec_settings({"FACE_REC_MEMORY_LIMIT_GB": limit if limit > 0 else None})
        console.print(f"\n[green]‚úÖ Ustawienie zapisane.[/green]")
    except ValueError: console.print("[red]B≈Çƒôdna warto≈õƒá.[/red]")
    Prompt.ask("\n[bold]Naci≈õnij Enter...[/]")

# --- G≈Å√ìWNY KONTROLER APLIKACJI ---

async def run_face_recognition_menu():
    """G≈Ç√≥wna funkcja uruchamiajƒÖca ca≈Çe menu rozpoznawania twarzy."""
    console.clear()
    if not _check_dependencies():
        Prompt.ask("\n[yellow]Brak kluczowych zale≈ºno≈õci. Naci≈õnij Enter...[/yellow]"); return
    _initialize_deepface_env()
    
    while True:
        console.clear()
        menu_items = [
            ("Zaindeksuj nowe zdjƒôcia", "index"),
            ("Rozpoznaj i oznacz twarze", "recognize"),
            ("ZarzƒÖdzaj znanymi osobami", "manage_people"),
            ("PrzeglƒÖdaj otagowane twarze", "review"),
            ("ZarzƒÖdzaj modelami AI", "models"),
            ("Ustaw limit pamiƒôci RAM dla AI", "limit"),
            ("Wr√≥ƒá do menu g≈Ç√≥wnego", "exit")
        ]
        selected_action = await create_interactive_menu(menu_items, "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Mened≈ºer Rozpoznawania Twarzy üë®‚Äçüë©‚Äçüëß‚Äçüë¶", border_style="blue")
        if selected_action in ("exit", None): break
        
        async def _select_model(action_text: str) -> Optional[str]:
            items = [(f"{m['name']}\n[dim]{m['description']}[/dim]", m['name']) for m in AVAILABLE_MODELS] + [("Anuluj", "cancel")]
            model = await create_interactive_menu(items, f"Wybierz model AI do {action_text}")
            if model in ("cancel", None): return None
            if not await _is_model_downloaded(model):
                console.print(f"[bold red]Model '{model}' nie jest pobrany! Pobierz go w mened≈ºerze.[/bold red]"); await Prompt.ask("\nEnter..."); return None
            return model

        if selected_action in ("index", "recognize", "manage_people"):
            action_map = {"index": "indeksowania", "recognize": "rozpoznawania", "manage_people": "zarzƒÖdzania osobami"}
            model = await _select_model(action_map[selected_action])
            if model:
                if selected_action == "index": await index_faces(model)
                elif selected_action == "recognize": await recognize_and_tag_faces(model)
                elif selected_action == "manage_people": await manage_people(model)
                Prompt.ask("\n[bold]Operacja zako≈Ñczona. Naci≈õnij Enter...[/]")
        
        elif selected_action == "review": await review_tagged_faces()
        elif selected_action == "models": await manage_ai_models()
        elif selected_action == "limit": await memory_limit_menu()
