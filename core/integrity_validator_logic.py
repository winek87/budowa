# -*- coding: utf-8 -*-

# plik: core/integrity_validator_logic.py
# Wersja 9.0 - Pe≈Çna integracja z asynchronicznym modu≈Çem bazy danych
#
# ##############################################################################
# ===                        MODU≈Å WALIDATORA INTEGRALNO≈öCI                  ===
# ##############################################################################
#
# "Walidator Integralno≈õci" to zaawansowany zestaw narzƒôdzi do "sprzƒÖtania"
# i weryfikacji pobranej kolekcji. Pozwala na:
#
#  - Obliczanie i zapisywanie sum kontrolnych (hash MD5) dla plik√≥w.
#  - Wyszukiwanie "duch√≥w" (wpis√≥w w bazie bez pliku na dysku) i "sierot"
#    (plik√≥w na dysku bez wpisu w bazie).
#  - Analizƒô sp√≥jno≈õci miƒôdzy datƒÖ w metadanych a lokalizacjƒÖ pliku.
#  - Interaktywne zarzƒÖdzanie duplikatami plik√≥w na podstawie ich zawarto≈õci.
#
################################################################################

# --- G≈Å√ìWNE IMPORTY ---
import asyncio
import hashlib
import os
import json
import logging
import uuid
from pathlib import Path
from typing import List, Dict, Set, Optional, Tuple
from datetime import datetime

# --- Zale≈ºno≈õci zewnƒôtrzne (opcjonalne) ---
try:
    import exiftool
    EXIFTOOL_AVAILABLE = True
except ImportError:
    EXIFTOOL_AVAILABLE = False

# --- Importy asynchroniczne ---
import aiosqlite

# --- IMPORTY Z BIBLIOTEKI `rich` ---
from rich.console import Console, Group
from rich.panel import Panel
from rich.text import Text
from rich.live import Live
from rich.prompt import Prompt, Confirm
from rich.table import Table
from rich.progress import Progress
from rich.align import Align
from rich.layout import Layout

# --- IMPORTY Z W≈ÅASNYCH MODU≈Å√ìW ---
from .config import DATABASE_FILE, DOWNLOADS_DIR_BASE, LOCAL_SCANNER_DIRECTORIES
from .utils import create_interactive_menu, _interactive_file_selector, get_key, _parse_metadata_for_display
# Importujemy nowƒÖ, dedykowanƒÖ funkcjƒô do zapisu plik√≥w lokalnych
from .database import add_local_file_entry

# --- Inicjalizacja i Konfiguracja Modu≈Çu ---
#console = Console(record=True)
console = Console()
logger = logging.getLogger(__name__)


# ##############################################################################
# ===           SEKCJA 1: FUNKCJE POMOCNICZE (ASYNC & EFFICIENT)             ===
# ##############################################################################

async def _calculate_hash_for_file(file_path: Path) -> Optional[str]:
    """
    Asynchronicznie i wydajnie oblicza hash MD5 dla podanego pliku.

    Funkcja ta czyta plik w ma≈Çych kawa≈Çkach (8192 bajty), aby nie obciƒÖ≈ºaƒá
    nadmiernie pamiƒôci RAM. Po odczytaniu ka≈ºdego kawa≈Çka, u≈ºywa `await
    asyncio.sleep(0)`, aby oddaƒá kontrolƒô do pƒôtli zdarze≈Ñ, co zapobiega
    blokowaniu interfejsu u≈ºytkownika podczas hashowania du≈ºych plik√≥w.

    Args:
        file_path (Path): ≈öcie≈ºka do pliku, dla kt√≥rego ma byƒá obliczony hash.

    Returns:
        Optional[str]: Hash MD5 jako string heksadecymalny, lub None w przypadku
                       b≈Çƒôdu odczytu pliku.
    """
    logger.debug(f"Rozpoczynam obliczanie hasha MD5 dla pliku '{file_path.name}'...")
    hasher = hashlib.md5()
    try:
        # U≈ºywamy `asyncio.to_thread`, aby ca≈Ça operacja plikowa
        # (otwarcie, czytanie w pƒôtli, zamkniƒôcie) odby≈Ça siƒô w osobnym wƒÖtku.
        def read_and_hash():
            with open(file_path, "rb") as f:
                while chunk := f.read(8192):
                    hasher.update(chunk)
            return hasher.hexdigest()

        file_hash = await asyncio.to_thread(read_and_hash)
        
        logger.debug(f"Obliczono hash dla '{file_path.name}': {file_hash}")
        return file_hash
        
    except (IOError, OSError) as e:
        logger.error(f"B≈ÇƒÖd odczytu pliku '{file_path}' podczas hashowania: {e}", exc_info=True)
        return None


async def _get_all_disk_paths(root_dir: Path) -> Set[Path]:
    """
    Asynchronicznie i wydajnie skanuje podany folder i wszystkie jego
    podfoldery w poszukiwaniu plik√≥w.

    U≈ºywa `loop.run_in_executor`, aby ca≈Ça, potencjalnie d≈Çuga operacja
    skanowania dysku odby≈Ça siƒô w osobnym wƒÖtku, nie blokujƒÖc g≈Ç√≥wnej
    pƒôtli `asyncio` i interfejsu u≈ºytkownika.

    Args:
        root_dir (Path): G≈Ç√≥wny folder do przeskanowania.

    Returns:
        Set[Path]: Zbi√≥r ze wszystkimi znalezionymi, absolutnymi ≈õcie≈ºkami
                   do plik√≥w.
    """
    disk_paths: Set[Path] = set()
    logger.info(f"Rozpoczynam asynchroniczne skanowanie dysku w folderze: {root_dir}")
    
    # Pobierz aktualnie dzia≈ÇajƒÖcƒÖ pƒôtlƒô zdarze≈Ñ
    loop = asyncio.get_running_loop()
    
    def scan_directory():
        """
        Funkcja pomocnicza, kt√≥ra wykonuje blokujƒÖcƒÖ operacjƒô skanowania.
        """
        logger.debug("Uruchamiam blokujƒÖcƒÖ operacjƒô rglob w osobnym wƒÖtku...")
        for path in root_dir.rglob('*'):
            if path.is_file():
                disk_paths.add(path.resolve())
    
    # Uruchom funkcjƒô skanujƒÖcƒÖ w puli wƒÖtk√≥w i poczekaj na jej zako≈Ñczenie
    await loop.run_in_executor(None, scan_directory)
    
    logger.info(f"Zako≈Ñczono skanowanie dysku. Znaleziono {len(disk_paths)} plik√≥w.")
    return disk_paths


async def _resolve_duplicates_interactively(duplicate_set: List[Dict]) -> Dict:
    """
    Wy≈õwietla interfejs "obok siebie" do rozwiƒÖzania pojedynczego zestawu duplikat√≥w.

    Funkcja ta:
    1.  Prezentuje dwa pliki z zestawu duplikat√≥w w dw√≥ch panelach,
        wy≈õwietlajƒÖc ich szczeg√≥≈Çowe metadane.
    2.  Automatycznie sugeruje zachowanie pliku o wiƒôkszym rozmiarze na dysku.
    3.  Pozwala u≈ºytkownikowi na nawigacjƒô (strza≈Çki lewo/prawo) w celu
        zmiany pliku, kt√≥ry ma zostaƒá zachowany.
    4.  Obs≈Çuguje akcje: zatwierdzenie (Enter), pominiƒôcie (P) i wyj≈õcie (Q).

    Args:
        duplicate_set (List[Dict]): Lista dw√≥ch s≈Çownik√≥w, gdzie ka≈ºdy
            s≈Çownik zawiera szczeg√≥≈Çowe informacje o jednym z duplikat√≥w.

    Returns:
        Dict: S≈Çownik opisujƒÖcy akcjƒô podjƒôtƒÖ przez u≈ºytkownika,
              np. {"action": "resolve", "keep": {...}, "delete": [{...}]}.
    """
    selected_to_keep = 0
    # Inteligentne, wstƒôpne zaznaczenie pliku o wiƒôkszym rozmiarze
    try:
        size_a_str = duplicate_set[0].get('size', '0 MB').split(' ')[0].replace(',', '.')
        size_b_str = duplicate_set[1].get('size', '0 MB').split(' ')[0].replace(',', '.')
        if float(size_b_str) > float(size_a_str):
            selected_to_keep = 1
    except (ValueError, IndexError) as e:
        logger.debug(f"Nie uda≈Ço siƒô automatycznie por√≥wnaƒá rozmiar√≥w plik√≥w: {e}")
        pass

    def generate_layout() -> Layout:
        """Wewnƒôtrzna funkcja renderujƒÖca interfejs por√≥wnawczy."""
        layout = Layout()
        layout.split_row(Layout(name="left"), Layout(name="right"))
        
        for i, file_info in enumerate(duplicate_set):
            is_kept = (i == selected_to_keep)
            status_text = Text("‚≠ê ZACHOWAJ", style="bold green") if is_kept else Text("üóëÔ∏è Usu≈Ñ", style="dim")
            
            table = Table.grid(expand=True, padding=(0, 1))
            table.add_column(style="cyan", justify="right", width=15); table.add_column()
            
            try:
                relative_path = str(file_info['path'].relative_to(DOWNLOADS_DIR_BASE))
            except ValueError:
                relative_path = str(file_info['path'])
                
            table.add_row("ID w Bazie:", str(file_info.get('id', 'Brak')))
            table.add_row("≈öcie≈ºka:", relative_path)
            table.add_row("‚îÄ" * 15, "‚îÄ" * 30)
            table.add_row("Data:", file_info.get('date', 'Brak'))
            table.add_row("Rozmiar:", file_info.get('size', 'Brak'))
            table.add_row("Wymiary:", file_info.get('dimensions', 'Brak'))
            table.add_row("Typ Pliku:", file_info.get('type', 'Brak'))
            table.add_row("‚îÄ" * 15, "‚îÄ" * 30)
            table.add_row("Aparat:", file_info.get('camera', 'Brak'))
            table.add_row("Ekspozycja:", file_info.get('exposure', 'Brak'))
            table.add_row("GPS:", file_info.get('gps', 'Brak'))
            
            panel_content = Group(Align.center(status_text), table)
            layout["left" if i == 0 else "right"].update(
                Panel(panel_content, title=f"Plik {'A' if i == 0 else 'B'}", border_style="green" if is_kept else "default")
            )
            
        footer = Align.center(Text("[bold]L/P[/](wybierz)‚Ä¢[bold]ENTER[/](zatwierd≈∫)‚Ä¢[bold]P[/](pomi≈Ñ)‚Ä¢[bold]Q[/](zako≈Ñcz)"))
        title_text = f"Wybierz plik do ZACHOWANIA\n[dim]Hash: {duplicate_set[0].get('hash', 'Brak')}[/dim]"
        
        main_layout = Layout()
        main_layout.split_column(Layout(Align.center(Text(title_text)), size=3), layout, Layout(footer, size=1))
        return main_layout
        
    # G≈Ç√≥wna pƒôtla interaktywna
    with Live(generate_layout(), screen=True, auto_refresh=False, transient=True) as live:
        while True:
            live.update(generate_layout(), refresh=True)
            key = await asyncio.to_thread(get_key)
            if not key: continue
            
            if key.upper() == "Q" or key == "ESC": return {"action": "quit"}
            if key.upper() == "P": return {"action": "skip"}
            if key in ["LEFT", "RIGHT"]: selected_to_keep = 1 - selected_to_keep
            if key == "ENTER":
                to_keep = duplicate_set[selected_to_keep]
                to_delete = [duplicate_set[1 - selected_to_keep]]
                return {"action": "resolve", "keep": to_keep, "delete": to_delete}


# ##############################################################################
# ===                    SEKCJA 2: G≈Å√ìWNE FUNKCJE WALIDATORA                 ===
# ##############################################################################

async def verify_file_existence():
    """
    Weryfikuje, czy pliki zarejestrowane w bazie danych jako 'downloaded'
    faktycznie istniejƒÖ na dysku pod zapisanƒÖ ≈õcie≈ºkƒÖ `final_path`.

    Proces:
    1.  Asynchronicznie pobiera z bazy danych listƒô wszystkich plik√≥w,
        kt√≥re powinny istnieƒá na dysku.
    2.  Iteruje przez tƒô listƒô, sprawdzajƒÖc istnienie ka≈ºdego pliku (operacja
        wykonywana w osobnym wƒÖtku, aby nie blokowaƒá UI).
    3.  Je≈õli znajdzie "pliki-duchy" (wpisy w bazie bez pliku na dysku),
        generuje szczeg√≥≈Çowy raport z listƒÖ brakujƒÖcych plik√≥w i sugeruje
        dalsze kroki.
    """
    console.clear()
    logger.info("Uruchamiam Weryfikator Istnienia Plik√≥w (Baza vs. Dysk)...")
    console.print(Panel("üëª Weryfikator Istnienia Plik√≥w ('Duchy' w bazie) üëª", expand=False, style="bold yellow"))

    try:
        # Krok 1: Pobierz listƒô plik√≥w z bazy
        async with aiosqlite.connect(DATABASE_FILE) as conn:
            conn.row_factory = aiosqlite.Row
            query = "SELECT id, final_path, filename FROM downloaded_media WHERE status = 'downloaded' AND final_path IS NOT NULL AND final_path != ''"
            cursor = await conn.execute(query)
            records_to_check = await cursor.fetchall()

        if not records_to_check:
            logger.warning("Nie znaleziono w bazie ≈ºadnych plik√≥w o statusie 'downloaded' do weryfikacji.")
            console.print("\n[green]Nie znaleziono w bazie ≈ºadnych plik√≥w ze statusem 'downloaded' do weryfikacji.[/green]")
            return

        # Krok 2: Sprawd≈∫ istnienie plik√≥w na dysku
        missing_files = []
        with Progress(console=console, transient=True) as progress:
            task = progress.add_task("[green]Sprawdzanie plik√≥w na dysku...", total=len(records_to_check))
            for record in records_to_check:
                file_path = Path(record['final_path'])
                if not await asyncio.to_thread(file_path.exists):
                    missing_files.append({
                        "id": record['id'],
                        "path": str(file_path),
                        "filename": record['filename']
                    })
                    logger.warning(f"Brak pliku na dysku dla ID={record['id']}: {file_path}")
                progress.update(task, advance=1)

        # Krok 3: Wy≈õwietl wyniki
        if not missing_files:
            logger.info("Weryfikacja zako≈Ñczona pomy≈õlnie. Wszystkie pliki z bazy istniejƒÖ na dysku.")
            console.print(f"\n[bold green]‚úÖ Weryfikacja zako≈Ñczona. Wszystkie {len(records_to_check)} pliki z bazy danych istniejƒÖ na dysku.[/bold green]")
        else:
            logger.error(f"Znaleziono {len(missing_files)} brakujƒÖcych plik√≥w ('duch√≥w')!")
            console.print(f"\n[bold red]‚ö†Ô∏è Znaleziono {len(missing_files)} brakujƒÖcych plik√≥w (wpisy w bazie bez pliku na dysku):[/bold red]")
            
            table = Table(title="Lista BrakujƒÖcych Plik√≥w ('Duchy')")
            table.add_column("ID Wpisu", style="cyan", justify="right")
            table.add_column("Oczekiwana ≈öcie≈ºka", style="red")
            for missing in missing_files:
                table.add_row(str(missing['id']), missing['path'])
            
            console.print(table)
            console.print("\n[yellow]Powy≈ºsze pliki zosta≈Çy prawdopodobnie usuniƒôte lub przeniesione rƒôcznie.[/yellow]")
            console.print("[dim]U≈ºyj 'Narzƒôdzia Zaawansowane -> Edytor Bazy Danych', aby usunƒÖƒá te martwe wpisy.[/dim]")

    except aiosqlite.Error as e:
        logger.critical("B≈ÇƒÖd bazy danych podczas weryfikacji istnienia plik√≥w.", exc_info=True)
        console.print(f"[bold red]WystƒÖpi≈Ç b≈ÇƒÖd bazy danych: {e}[/bold red]")
    except Exception as e:
        logger.critical("WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd podczas weryfikacji istnienia plik√≥w.", exc_info=True)
        console.print(f"[bold red]WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd. Sprawd≈∫ logi.[/bold red]")


async def verify_and_write_hashes():
    """
    Skanuje pliki w bazie danych, oblicza dla nich sumy kontrolne MD5
    i zapisuje je w kolumnie `file_hash`.

    Proces:
    1.  Pobiera z bazy listƒô wszystkich plik√≥w o statusie 'downloaded',
        kt√≥re nie majƒÖ jeszcze obliczonego hasha.
    2.  Dla ka≈ºdego pliku:
        a) Sprawdza, czy plik istnieje na dysku.
        b) Wywo≈Çuje `_calculate_hash_for_file` do obliczenia sumy kontrolnej.
    3.  Zapisuje wyniki do bazy danych w partiach (batches), aby
        zminimalizowaƒá liczbƒô transakcji i zwiƒôkszyƒá wydajno≈õƒá.
    """
    console.clear()
    logger.info("Uruchamiam weryfikacjƒô i zapis sum kontrolnych (MD5)...")
    console.print(Panel("üßÆ Obliczanie i Zapis Sum Kontrolnych (MD5) üßÆ", expand=False, style="bold yellow"))
    
    try:
        async with aiosqlite.connect(DATABASE_FILE) as conn:
            conn.row_factory = aiosqlite.Row
            
            # Krok 1: Pobierz listƒô plik√≥w do przetworzenia
            query = "SELECT id, final_path FROM downloaded_media WHERE status = 'downloaded' AND (file_hash IS NULL OR file_hash = '')"
            cursor = await conn.execute(query)
            records_to_hash = await cursor.fetchall()

            if not records_to_hash:
                logger.info("Wszystkie pobrane pliki w bazie majƒÖ ju≈º obliczone sumy kontrolne.")
                console.print("\n[bold green]‚úÖ Wszystkie pobrane pliki w bazie majƒÖ ju≈º obliczone sumy kontrolne.[/bold green]")
                return

            logger.info(f"Znaleziono {len(records_to_hash)} plik√≥w do obliczenia hasha.")
            
            # Krok 2: Przetwarzaj pliki i zbieraj wyniki w partii
            updates_batch: List[Tuple[str, int]] = []
            BATCH_SIZE = 100
            
            with Progress(console=console, transient=True) as progress:
                task = progress.add_task("[cyan]Obliczanie hashy MD5...", total=len(records_to_hash))
                for record in records_to_hash:
                    file_path = Path(record['final_path'])
                    if await asyncio.to_thread(file_path.exists):
                        file_hash = await _calculate_hash_for_file(file_path)
                        if file_hash:
                            updates_batch.append((file_hash, record['id']))
                    else:
                        logger.warning(f"Pominiƒôto obliczanie hasha dla nieistniejƒÖcego pliku: {file_path}")
                    
                    # Krok 3: Zapisz partiƒô do bazy, je≈õli osiƒÖgnƒô≈Ça limit
                    if len(updates_batch) >= BATCH_SIZE:
                        await conn.executemany("UPDATE downloaded_media SET file_hash = ? WHERE id = ?", updates_batch)
                        await conn.commit()
                        logger.info(f"Zapisano partiƒô {len(updates_batch)} hashy do bazy danych.")
                        updates_batch.clear()
                        
                    progress.update(task, advance=1)

            # Krok 4: Zapisz ostatniƒÖ, niepe≈ÇnƒÖ partiƒô
            if updates_batch:
                await conn.executemany("UPDATE downloaded_media SET file_hash = ? WHERE id = ?", updates_batch)
                await conn.commit()
                logger.info(f"Zapisano ostatniƒÖ partiƒô {len(updates_batch)} hashy do bazy danych.")
                
            console.print(f"\n[bold green]‚úÖ Zako≈Ñczono. Zaktualizowano sumy kontrolne dla {len(records_to_hash)} plik√≥w.[/bold green]")
            
    except aiosqlite.Error as e:
        logger.critical("Krytyczny b≈ÇƒÖd bazy danych podczas zapisu hashy.", exc_info=True)
        console.print(f"[bold red]WystƒÖpi≈Ç b≈ÇƒÖd bazy danych: {e}[/bold red]")
    except Exception as e:
        logger.critical("WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd podczas obliczania hashy.", exc_info=True)
        console.print(f"[bold red]WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd. Sprawd≈∫ logi.[/bold red]")


async def find_and_fix_inconsistencies():
    """
    Znajduje i pozwala naprawiƒá niesp√≥jno≈õci miƒôdzy wpisami w bazie danych
    a fizycznymi plikami na dysku.

    Operacja ta identyfikuje dwa typy problem√≥w:
    1.  **Duchy (Ghosts):** Wpisy w bazie, dla kt√≥rych nie istnieje plik na dysku.
    2.  **Sieroty (Orphans):** Pliki na dysku, dla kt√≥rych nie ma wpisu w bazie.

    Skanuje zar√≥wno g≈Ç√≥wnƒÖ bibliotekƒô (`DOWNLOADS_DIR_BASE`), jak i wszystkie
    foldery zindeksowane z `LOCAL_SCANNER_DIRECTORIES`.
    """
    console.clear()
    logger.info("Uruchamiam wyszukiwanie niesp√≥jno≈õci (Baza Danych vs. Dysk)...")
    console.print(Panel("üëª Wyszukiwanie Niesp√≥jno≈õci (Duchy i Sieroty)", expand=False, style="bold yellow"))
    
    try:
        # Krok 1: Asynchronicznie wczytaj dane z bazy i z dysku
        with console.status("[cyan]Wczytywanie rekord√≥w z bazy danych...[/]"):
            async with aiosqlite.connect(DATABASE_FILE) as conn:
                conn.row_factory = aiosqlite.Row
                query = "SELECT id, final_path FROM downloaded_media WHERE final_path IS NOT NULL AND final_path != ''"
                cursor = await conn.execute(query)
                db_records = [{'id': row['id'], 'path': Path(row['final_path']).resolve()} for row in await cursor.fetchall()]
        db_paths = {rec['path'] for rec in db_records}
        
        with console.status("[cyan]Skanowanie plik√≥w na dysku (mo≈ºe potrwaƒá)...[/]"):
            # NOWA LOGIKA: Skanuj wszystkie zdefiniowane ≈õcie≈ºki
            disk_paths = set()
            paths_to_scan = [Path(DOWNLOADS_DIR_BASE)] + [Path(p) for p in LOCAL_SCANNER_DIRECTORIES]
            
            for root_dir in paths_to_scan:
                if await asyncio.to_thread(root_dir.is_dir):
                    logger.info(f"Skanujƒô folder: {root_dir}")
                    scanned_paths = await _get_all_disk_paths(root_dir)
                    disk_paths.update(scanned_paths)
                else:
                    logger.warning(f"≈öcie≈ºka '{root_dir}' z konfiguracji nie jest prawid≈Çowym folderem i zostanie pominiƒôta.")

        logger.info(f"Por√≥wnujƒô {len(db_paths)} wpis√≥w z bazy z {len(disk_paths)} plikami na dysku...")
        
        # Krok 2: Zidentyfikuj "duchy" i "sieroty"
        db_ghosts = [rec for rec in db_records if rec['path'] not in disk_paths]
        disk_orphans = sorted([path for path in disk_paths if path not in db_paths])

        # Krok 3: Obs≈Çuga "duch√≥w" (wpis√≥w w bazie bez plik√≥w)
        if db_ghosts:
            console.print(f"\n[bold yellow]Znaleziono {len(db_ghosts)} 'duch√≥w' w bazie danych (wpisy bez plik√≥w).[/]")
            if Confirm.ask("[cyan]Czy chcesz usunƒÖƒá te martwe wpisy z bazy danych?[/]", default=True):
                ghost_ids = [ghost['id'] for ghost in db_ghosts]
                async with aiosqlite.connect(DATABASE_FILE) as conn:
                    placeholders = ','.join(['?'] * len(ghost_ids))
                    await conn.execute(f"DELETE FROM downloaded_media WHERE id IN ({placeholders})", ghost_ids)
                    await conn.commit()
                logger.info(f"Usuniƒôto {len(db_ghosts)} wpis√≥w-duch√≥w z bazy danych.")
        
        # Krok 4: Obs≈Çuga "sierot" (plik√≥w na dysku bez wpis√≥w w bazie)
        if disk_orphans:
            console.print(f"\n[bold yellow]Znaleziono {len(disk_orphans)} 'sierot' na dysku (pliki bez wpis√≥w w bazie).[/]")
            selected_files = await _interactive_file_selector(disk_orphans, "Wybierz 'osierocone' pliki do zarzƒÖdzania")

            if selected_files:
                action = Prompt.ask(f"\nWybrano [cyan]{len(selected_files)}[/cyan] plik√≥w. Co z nimi zrobiƒá?", choices=["importuj", "usu≈Ñ", "anuluj"], default="anuluj")
                
                if action == "importuj":
                    if not EXIFTOOL_AVAILABLE:
                        console.print(Panel("[bold red]B≈ÇƒÖd: Brak 'pyexiftool'![/bold red]\nOperacja importu wymaga tej biblioteki.", title="Brak Zale≈ºno≈õci"))
                    else:
                        with Progress(console=console, transient=True) as progress_bar:
                            task = progress_bar.add_task("[green]Importujƒô do bazy...", total=len(selected_files))
                            with exiftool.ExifToolHelper() as et:
                                for file_path in selected_files:
                                    try:
                                        metadata_list = await asyncio.to_thread(et.get_metadata, str(file_path))
                                        if metadata_list:
                                            # U≈ºywamy nowej, poprawnej funkcji z `database.py`
                                            await add_local_file_entry(file_path, metadata_list[0])
                                    except Exception:
                                        logger.error(f"B≈ÇƒÖd importu {file_path.name}", exc_info=True)
                                    progress_bar.update(task, advance=1)
                elif action == "usu≈Ñ":
                    if Confirm.ask(f"\n[bold red]Czy na pewno chcesz TRWALE usunƒÖƒá {len(selected_files)} zaznaczonych plik√≥w z dysku?[/]"):
                        with Progress(console=console, transient=True) as progress_bar:
                            task = progress_bar.add_task("[red]Usuwam z dysku...", total=len(selected_files))
                            for file_path in selected_files:
                                try:
                                    await asyncio.to_thread(os.remove, file_path)
                                except OSError:
                                    logger.error(f"B≈ÇƒÖd usuwania {file_path.name}", exc_info=True)
                                progress_bar.update(task, advance=1)
        
        if not db_ghosts and not disk_orphans:
            console.print("\n[bold green]‚úÖ Weryfikacja zako≈Ñczona. Nie znaleziono ≈ºadnych niesp√≥jno≈õci.[/bold green]")

    except aiosqlite.Error as e:
        logger.critical("Krytyczny b≈ÇƒÖd bazy danych podczas wyszukiwania niesp√≥jno≈õci.", exc_info=True)
    except Exception as e:
        logger.critical("WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd podczas analizy niesp√≥jno≈õci.", exc_info=True)


async def analyze_metadata_consistency():
    """
    Sprawdza sp√≥jno≈õƒá danych miƒôdzy fizycznƒÖ lokalizacjƒÖ pliku a datƒÖ
    zapisanƒÖ w jego metadanych w bazie danych.

    Proces:
    1.  Pobiera z bazy wszystkie wpisy, kt√≥re majƒÖ zar√≥wno ≈õcie≈ºkƒô (`final_path`),
        jak i datƒô (`DateTime`) w metadanych JSON.
    2.  Dla ka≈ºdego wpisu, por√≥wnuje rok i miesiƒÖc z daty w bazie z rokiem
        i miesiƒÖcem wynikajƒÖcym ze struktury folder√≥w (`.../ROK/MIESIƒÑC/...`).
    3.  Je≈õli znajdzie niesp√≥jno≈õci, generuje szczeg√≥≈Çowy raport w formie tabeli,
        wskazujƒÖc, kt√≥re pliki mogƒÖ znajdowaƒá siƒô w niew≈Ça≈õciwych folderach.
    """
    console.clear()
    logger.info("Uruchamiam analizƒô sp√≥jno≈õci metadanych (≈öcie≈ºka vs. Baza)...")
    console.print(Panel("üîó Analiza Sp√≥jno≈õci Metadanych (≈öcie≈ºka vs. Data w Bazie) üîó", expand=False, style="bold yellow"))
    
    mismatches = []
    
    try:
        async with aiosqlite.connect(DATABASE_FILE) as conn:
            conn.row_factory = aiosqlite.Row
            query = """
                SELECT id, final_path, json_extract(metadata_json, '$.DateTime') as dt_from_json
                FROM downloaded_media
                WHERE status = 'downloaded' AND dt_from_json IS NOT NULL AND final_path IS NOT NULL AND final_path != ''
            """
            
            with Progress(console=console, transient=True) as progress:
                cursor = await conn.execute(query)
                all_records = await cursor.fetchall()
                
                if not all_records:
                    logger.warning("Nie znaleziono plik√≥w z kompletnymi danymi do analizy sp√≥jno≈õci.")
                    console.print("\n[green]Nie znaleziono plik√≥w z wymaganymi danymi do analizy.[/green]")
                    return

                task = progress.add_task("[cyan]Analizowanie sp√≥jno≈õci...", total=len(all_records))
                for row in all_records:
                    try:
                        path = Path(row['final_path'])
                        # Wymagane jest, aby ≈õcie≈ºka mia≈Ça co najmniej 2 poziomy folder√≥w (ROK/MIESIƒÑC)
                        if len(path.parts) < 3:
                            logger.debug(f"Pominiƒôto rekord ze zbyt kr√≥tkƒÖ ≈õcie≈ºkƒÖ: ID {row['id']}")
                            continue
                            
                        db_datetime = datetime.fromisoformat(row['dt_from_json'].replace('Z', '+00:00'))
                        db_year, db_month = db_datetime.year, db_datetime.month

                        # Pobierz rok i miesiƒÖc ze ≈õcie≈ºki (przedostatni i ostatni folder)
                        path_month = int(path.parent.name)
                        path_year = int(path.parent.parent.name)

                        if db_year != path_year or db_month != path_month:
                            mismatches.append({
                                'path': str(path),
                                'db_date': f"{db_year}-{db_month:02d}",
                                'path_date': f"{path_year}-{path_month:02d}"
                            })
                    except (ValueError, IndexError, TypeError, AttributeError) as e:
                        logger.debug(f"Pominiƒôto rekord z powodu b≈Çƒôdu parsowania (≈õcie≈ºka/data): ID {row['id']}. B≈ÇƒÖd: {e}")
                        continue
                    finally:
                         progress.update(task, advance=1)

        if not mismatches:
            logger.info("Analiza zako≈Ñczona. Sp√≥jno≈õƒá metadanych idealna.")
            console.print("\n[bold green]‚úÖ Sp√≥jno≈õƒá metadanych idealna! Wszystkie daty w ≈õcie≈ºkach zgadzajƒÖ siƒô z bazƒÖ danych.[/bold green]")
        else:
            logger.error(f"Znaleziono {len(mismatches)} niesp√≥jno≈õci miƒôdzy ≈õcie≈ºkƒÖ a metadanymi.")
            console.print(f"\n[bold red]‚ö†Ô∏è Znaleziono {len(mismatches)} niesp√≥jno≈õci:[/bold red]")
            
            table = Table(title="Niesp√≥jno≈õci Metadanych (≈öcie≈ºka vs. Baza)")
            table.add_column("≈öcie≈ºka Pliku", style="cyan"); table.add_column("Data wg Bazy", style="yellow"); table.add_column("Data wg ≈öcie≈ºki", style="red")
            for item in mismatches[:30]: table.add_row(item['path'], item['db_date'], item['path_date'])
            console.print(table)
            
            if len(mismatches) > 30: console.print(f"  ... i {len(mismatches) - 30} wiƒôcej.")
                
            console.print("\n[yellow]Powy≈ºsze niesp√≥jno≈õci mogƒÖ wskazywaƒá na b≈ÇƒÖd w sortowaniu lub rƒôczne przeniesienie plik√≥w.[/yellow]")
            console.print("[dim]U≈ºyj 'Skaner i Mened≈ºer -> Sprawd≈∫ i napraw LOKALIZACJE plik√≥w', aby to naprawiƒá.[/dim]")

    except aiosqlite.Error as e:
        logger.critical("B≈ÇƒÖd bazy danych podczas analizy sp√≥jno≈õci.", exc_info=True)
    except Exception as e:
        logger.critical("WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd podczas analizy sp√≥jno≈õci.", exc_info=True)


async def find_duplicates_by_hash():
    """
    Uruchamia interaktywny mened≈ºer do wyszukiwania i rozwiƒÖzywania
    problemu duplikat√≥w plik√≥w na podstawie ich sum kontrolnych (hash MD5).

    Proces:
    1.  Wyszukuje w bazie danych wszystkie hashe MD5, kt√≥re wystƒôpujƒÖ wiƒôcej
        ni≈º raz.
    2.  Dla ka≈ºdej grupy duplikat√≥w, pobiera szczeg√≥≈Çowe metadane.
    3.  Prezentuje u≈ºytkownikowi interfejs `_resolve_duplicates_interactively`
        do podjƒôcia decyzji, kt√≥ry plik zachowaƒá.
    4.  Po zako≈Ñczeniu przeglƒÖdu, prosi o ostateczne potwierdzenie i bezpiecznie
        usuwa wybrane pliki z dysku oraz odpowiadajƒÖce im wpisy z bazy danych.
    """
    console.clear()
    logger.info("Uruchamiam Interaktywny Mened≈ºer Duplikat√≥w (wg hash MD5)...")
    console.print(Panel("üß© Mened≈ºer Duplikat√≥w Plik√≥w (wg zawarto≈õci) üß©", expand=False, style="bold yellow"))
    
    try:
        async with aiosqlite.connect(DATABASE_FILE) as conn:
            conn.row_factory = aiosqlite.Row
            
            # Krok 1: Znajd≈∫ hashe, kt√≥re majƒÖ duplikaty
            query_hashes = "SELECT file_hash FROM downloaded_media WHERE file_hash IS NOT NULL AND file_hash != '' GROUP BY file_hash HAVING COUNT(id) > 1"
            cursor = await conn.execute(query_hashes)
            duplicate_hashes = await cursor.fetchall()

            if not duplicate_hashes:
                logger.info("Nie znaleziono ≈ºadnych duplikat√≥w na podstawie sum kontrolnych.")
                console.print("\n[bold green]‚úÖ Nie znaleziono ≈ºadnych duplikat√≥w plik√≥w na podstawie ich zawarto≈õci.[/bold green]")
                return

            logger.warning(f"Znaleziono {len(duplicate_hashes)} zestawy potencjalnych duplikat√≥w. Rozpoczynam przeglƒÖd...")
            
            all_files_to_delete = []

            # Krok 2: Iteruj po ka≈ºdym zestawie duplikat√≥w
            for i, row in enumerate(duplicate_hashes):
                hash_val = row['file_hash']
                console.clear()
                console.print(Panel(f"[bold yellow]Zestaw duplikat√≥w {i + 1}/{len(duplicate_hashes)}[/]", expand=False))

                query_details = "SELECT id, final_path, metadata_json FROM downloaded_media WHERE file_hash = ?"
                cursor = await conn.execute(query_details, (hash_val,))
                files_in_set_raw = await cursor.fetchall()

                files_in_set = []
                for file_row in files_in_set_raw:
                    metadata = json.loads(file_row['metadata_json'] or '{}')
                    file_path = Path(file_row['final_path'])
                    # Wywo≈Çujemy scentralizowanƒÖ funkcjƒô z utils.py
                    display_info = _parse_metadata_for_display(metadata, file_path)
                    files_in_set.append({"id": file_row['id'], "path": file_path, "hash": hash_val, **display_info})

                if len(files_in_set) > 1:
                    resolution = await _resolve_duplicates_interactively(files_in_set)
                    if resolution.get("action") == "quit": break
                    if resolution.get("action") == "skip": continue
                    if resolution.get("action") == "resolve": all_files_to_delete.extend(resolution['delete'])

            # Krok 3: Podsumowanie i ostateczne usuniƒôcie
            if not all_files_to_delete:
                logger.info("PrzeglƒÖd zako≈Ñczony. Nie wybrano ≈ºadnych plik√≥w do usuniƒôcia.")
                return

            console.clear()
            console.print(Panel("[bold red]Podsumowanie Akcji Usuniƒôcia Duplikat√≥w[/]", expand=False))
            console.print(f"Wybrano [cyan]{len(all_files_to_delete)}[/cyan] plik√≥w do trwa≈Çego usuniƒôcia.")

            if Confirm.ask("\n[bold red]Czy na pewno chcesz TRWALE usunƒÖƒá te pliki z dysku i z bazy danych?[/]", default=False):
                ids_to_delete = [f['id'] for f in all_files_to_delete]
                
                with Progress(console=console, transient=True) as progress:
                    task = progress.add_task("[red]Usuwam pliki z dysku...", total=len(all_files_to_delete))
                    for file_info in all_files_to_delete:
                        try:
                            if await asyncio.to_thread(file_info['path'].exists):
                                await asyncio.to_thread(os.remove, file_info['path'])
                        except OSError as e:
                            logger.error(f"B≈ÇƒÖd usuwania pliku {file_info['path']}", exc_info=True)
                        progress.update(task, advance=1)

                with console.status("[bold red]Usuwam wpisy z bazy danych...[/]"):
                    placeholders = ','.join(['?'] * len(ids_to_delete))
                    await conn.execute(f"DELETE FROM downloaded_media WHERE id IN ({placeholders})", ids_to_delete)
                    await conn.commit()
                
                console.print(f"\n[bold green]‚úÖ Usuniƒôto {len(ids_to_delete)} duplikat√≥w.[/bold green]")
                logger.info(f"Usuniƒôto {len(ids_to_delete)} zduplikowanych plik√≥w i wpis√≥w w bazie.")
            else:
                logger.warning("Anulowano operacjƒô usuwania duplikat√≥w.")

    except aiosqlite.Error as e:
        logger.critical("B≈ÇƒÖd bazy danych podczas wyszukiwania duplikat√≥w.", exc_info=True)
        console.print(f"[bold red]WystƒÖpi≈Ç b≈ÇƒÖd bazy danych: {e}[/bold red]")
    except Exception as e:
        logger.critical("WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd podczas zarzƒÖdzania duplikatami.", exc_info=True)
        console.print(f"[bold red]WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd. Sprawd≈∫ logi.[/bold red]")


# ##############################################################################
# ===                    SEKCJA 3: G≈Å√ìWNA FUNKCJA URUCHOMIENIOWA             ===
# ##############################################################################

async def run_integrity_validator():
    """
    Wy≈õwietla i zarzƒÖdza interaktywnym menu dla "Walidatora Integralno≈õci".

    Ta funkcja jest "launcherem" dla ca≈Çego modu≈Çu. Jej zadaniem jest:
    1.  Zdefiniowanie opcji dostƒôpnych w menu.
    2.  Wywo≈Çanie uniwersalnej funkcji `create_interactive_menu` do wy≈õwietlenia
        interfejsu i obs≈Çu≈ºenia wyboru u≈ºytkownika.
    3.  Uruchomienie odpowiedniej akcji w zale≈ºno≈õci od decyzji u≈ºytkownika.
    """
    logger.info("Uruchamiam menu Walidatora Integralno≈õci Danych.")
    
    menu_items = [
        ("Sprawd≈∫ istnienie plik√≥w (Baza vs Dysk)", verify_file_existence),
        ("Oblicz i zapisz sumy kontrolne plik√≥w (hash MD5)", verify_and_write_hashes),
        ("Znajd≈∫ niesp√≥jno≈õci (pliki-sieroty i duchy)", find_and_fix_inconsistencies),
        ("Analizuj sp√≥jno≈õƒá metadanych (≈õcie≈ºka vs. data)", analyze_metadata_consistency),
        ("Znajd≈∫ i zarzƒÖdzaj duplikatami (wg zawarto≈õci)", find_duplicates_by_hash),
        ("Wr√≥ƒá do menu g≈Ç√≥wnego", "exit")
    ]

    while True:
        console.clear()
        selected_action = await create_interactive_menu(
            menu_items,
            "Walidator Integralno≈õci Danych",
            border_style="blue"
        )

        if selected_action == "exit" or selected_action is None:
            logger.info("Zamykanie Walidatora Integralno≈õci.")
            break

        # Uruchom wybrane narzƒôdzie
        await selected_action()
        
        # Popro≈õ o interakcjƒô przed ponownym wy≈õwietleniem menu
        Prompt.ask("\n[bold]Operacja zako≈Ñczona. Naci≈õnij Enter, aby wr√≥ciƒá do menu walidatora...[/]")
