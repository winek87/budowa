# -*- coding: utf-8 -*-

# plik: core/takeout_url_processor_logic.py
# Wersja 1.0 - Nowy modu≈Ç do naprawy z URL-i z Takeout
#
# ##############################################################################
# ===           MODU≈Å NAPRAWY Z U≈ªYCIEM URL-I Z GOOGLE TAKEOUT               ===
# ##############################################################################
#
# Ten modu≈Ç zawiera logikƒô dla narzƒôdzia, kt√≥re wykorzystuje unikalne adresy URL
# do zdjƒôƒá (pozyskane z archiwum Takeout) w celu ponownego przetworzenia
# i naprawy wpis√≥w w bazie danych, kt√≥re wcze≈õniej zako≈Ñczy≈Çy siƒô b≈Çƒôdem
# lub mia≈Çy niekompletne dane.
#
################################################################################

# --- G≈Å√ìWNE IMPORTY ---
import asyncio
import logging
from pathlib import Path

# --- Importy asynchroniczne ---
import aiosqlite
from playwright.async_api import async_playwright

# --- IMPORTY Z BIBLIOTEKI `rich` ---
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Confirm
from rich.progress import Progress

# --- IMPORTY Z W≈ÅASNYCH MODU≈Å√ìW ---
from .config import (
    SESSION_DIR, BROWSER_TYPE, BROWSER_ARGS, DEFAULT_HEADLESS_MODE,
    DOWNLOADS_DIR_BASE, DATABASE_FILE
)
# Reu≈ºywamy g≈Ç√≥wnego "m√≥zgu" z silnika Master do przetwarzania stron
from .master_logic import process_single_photo_page

# --- Inicjalizacja i Konfiguracja Modu≈Çu ---
console = Console(record=True)
logger = logging.getLogger(__name__)


async def _get_urls_to_process_from_db() -> list[str]:
    """
    Pobiera z bazy danych listƒô adres√≥w URL z Takeout dla plik√≥w,
    kt√≥re wymagajƒÖ ponownego przetworzenia.

    Szuka wpis√≥w ze statusem 'failed' (b≈ÇƒÖd pobierania) lub 'skipped'
    (pominiƒôty, potencjalnie z powodu braku metadanych online), kt√≥re
    jednocze≈õnie posiadajƒÖ zapisany `google_photos_url`.

    :return: Lista adres√≥w URL do przetworzenia.
    """
    logger.info("Pobieram z bazy listƒô URL-i z Takeout do naprawy...")
    try:
        async with aiosqlite.connect(DATABASE_FILE) as conn:
            query = """
                SELECT google_photos_url FROM downloaded_media
                WHERE status IN ('failed', 'skipped')
                AND google_photos_url IS NOT NULL
                AND google_photos_url != ''
            """
            cursor = await conn.execute(query)
            urls = [row[0] for row in await cursor.fetchall()]
            logger.info(f"Znaleziono {len(urls)} URL-i do naprawy.")
            return urls
    except aiosqlite.Error as e:
        logger.error(f"B≈ÇƒÖd podczas pobierania URL-i do naprawy: {e}", exc_info=True)
        return []

async def run_takeout_url_processor():
    """
    Uruchamia g≈Ç√≥wny proces naprawy z u≈ºyciem URL-i zapisanych z Takeout.

    Proces:
    1. Pobiera listƒô problematycznych URL-i z bazy danych.
    2. Prosi u≈ºytkownika o potwierdzenie.
    3. Uruchamia przeglƒÖdarkƒô i iteruje po li≈õcie URL-i.
    4. Dla ka≈ºdego URL-a, wywo≈Çuje potƒô≈ºnƒÖ funkcjƒô `process_single_photo_page`
       z modu≈Çu `master_logic`, kt√≥ra wykonuje pe≈Çen cykl pobierania,
       analizy i zapisu.
    """
    console.clear()
    logger.info("Uruchomiono narzƒôdzie do naprawy z URL-i z Takeout.")
    console.print(Panel("üîß Naprawa z U≈ºyciem URL-i z Takeout üîß", expand=False, style="bold green"))

    urls_to_process = await _get_urls_to_process_from_db()
    if not urls_to_process:
        console.print("\n[bold green]‚úÖ Nie znaleziono plik√≥w, kt√≥re mo≈ºna by naprawiƒá za pomocƒÖ tej metody.[/bold green]")
        return

    console.print(f"\nZnaleziono [bold cyan]{len(urls_to_process)}[/bold cyan] plik√≥w, kt√≥re mo≈ºna spr√≥bowaƒá pobraƒá/przeskanowaƒá ponownie.")
    if not Confirm.ask("[cyan]Czy chcesz kontynuowaƒá?[/]"):
        logger.warning("Operacja naprawy anulowana przez u≈ºytkownika.")
        return

    # Uruchomienie przeglƒÖdarki i pƒôtli przetwarzania
    try:
        async with async_playwright() as p:
            with console.status("[cyan]Uruchamianie przeglƒÖdarki...[/]"):
                context = await getattr(p, BROWSER_TYPE).launch_persistent_context(
                    Path(SESSION_DIR).expanduser(),
                    headless=DEFAULT_HEADLESS_MODE,
                    accept_downloads=True,
                    args=BROWSER_ARGS.get(BROWSER_TYPE)
                )
                page = await context.new_page()

            with Progress(console=console, transient=True) as progress:
                task = progress.add_task("[green]Przetwarzanie...", total=len(urls_to_process))
                for i, url in enumerate(urls_to_process):
                    short_url = url[:45] + "..." + url[-15:] if len(url) > 60 else url
                    progress.update(task, description=f"Praca nad [dim]{short_url}[/dim]")

                    # Wywo≈Çujemy g≈Ç√≥wny procesor z silnika Master, przekazujƒÖc mu URL z Takeout
                    success, status, metadata = await process_single_photo_page(
                        page, url, Path(DOWNLOADS_DIR_BASE), 'main'
                    )
                    
                    if success:
                        logger.info(f"Pomy≈õlnie przetworzono URL: {url} (status: {status})")
                    else:
                        logger.warning(f"Nie uda≈Ço siƒô przetworzyƒá URL: {url} (status: {status})")

                    progress.update(task, advance=1)
            
            await context.close()

        console.print("\n[bold green]‚úÖ Proces naprawy zako≈Ñczony.[/bold green]")
        logger.info("Zako≈Ñczono proces naprawy z u≈ºyciem URL-i z Takeout.")

    except Exception as e:
        logger.critical("WystƒÖpi≈Ç krytyczny b≈ÇƒÖd podczas procesu naprawy.", exc_info=True)
        console.print(f"\n[bold red]WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd. Sprawd≈∫ plik logu.[/bold red]")
